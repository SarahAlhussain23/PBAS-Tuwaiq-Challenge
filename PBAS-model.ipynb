{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: تثبيت المتطلبات الأساسية\n",
        "!pip install ultralytics==8.0.20\n",
        "!pip install supervision==0.15.0\n",
        "!pip install torch torchvision\n",
        "!pip install opencv-python\n",
        "!pip install pandas matplotlib seaborn\n",
        "!pip install scikit-learn\n",
        "!pip install tensorflow\n",
        "!pip install gdown\n",
        "!pip install lap\n",
        "!pip install filterpy\n",
        "!pip install deep-sort-realtime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 2404
        },
        "id": "uUg60cEdPGBT",
        "outputId": "e27a5f6c-3b1f-4499-e46a-8b13faa30a29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Ignored the following yanked versions: 8.0.129, 8.0.174, 8.0.177, 8.1.21, 8.1.31, 8.2.7, 8.2.47\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Ignored the following versions that require a different python version: 8.0.10 Requires-Python >=3.7,<=3.11; 8.0.11 Requires-Python >=3.7,<=3.11; 8.0.12 Requires-Python >=3.7,<=3.11; 8.0.13 Requires-Python >=3.7,<=3.11; 8.0.14 Requires-Python >=3.7,<=3.11; 8.0.15 Requires-Python >=3.7,<=3.11; 8.0.16 Requires-Python >=3.7,<=3.11; 8.0.17 Requires-Python >=3.7,<=3.11; 8.0.18 Requires-Python >=3.7,<=3.11; 8.0.19 Requires-Python >=3.7,<=3.11; 8.0.20 Requires-Python >=3.7,<=3.11; 8.0.21 Requires-Python >=3.7,<=3.11; 8.0.22 Requires-Python >=3.7,<=3.11; 8.0.23 Requires-Python >=3.7,<=3.11; 8.0.24 Requires-Python >=3.7,<=3.11; 8.0.25 Requires-Python >=3.7,<=3.11; 8.0.26 Requires-Python >=3.7,<=3.11; 8.0.27 Requires-Python >=3.7,<=3.11; 8.0.28 Requires-Python >=3.7,<=3.11; 8.0.29 Requires-Python >=3.7,<=3.11; 8.0.30 Requires-Python >=3.7,<=3.11; 8.0.31 Requires-Python >=3.7,<=3.11; 8.0.32 Requires-Python >=3.7,<=3.11; 8.0.33 Requires-Python >=3.7,<=3.11; 8.0.34 Requires-Python >=3.7,<=3.11; 8.0.7 Requires-Python >=3.7,<=3.11; 8.0.8 Requires-Python >=3.7,<=3.11; 8.0.9 Requires-Python >=3.7,<=3.11\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: Could not find a version that satisfies the requirement ultralytics==8.0.20 (from versions: 0.0.13, 0.0.14, 0.0.15, 0.0.16, 0.0.17, 0.0.18, 0.0.19, 0.0.20, 0.0.21, 0.0.22, 0.0.23, 0.0.24, 0.0.25, 0.0.26, 0.0.27, 0.0.28, 0.0.29, 0.0.30, 0.0.31, 0.0.32, 0.0.33, 0.0.34, 0.0.35, 0.0.36, 0.0.37, 0.0.38, 0.0.39, 0.0.40, 0.0.41, 0.0.42, 0.0.43, 0.0.44, 8.0.0, 8.0.1, 8.0.2, 8.0.3, 8.0.4, 8.0.5, 8.0.6, 8.0.35, 8.0.36, 8.0.37, 8.0.38, 8.0.39, 8.0.40, 8.0.41, 8.0.42, 8.0.43, 8.0.44, 8.0.45, 8.0.46, 8.0.47, 8.0.48, 8.0.49, 8.0.50, 8.0.51, 8.0.52, 8.0.53, 8.0.54, 8.0.55, 8.0.56, 8.0.57, 8.0.58, 8.0.59, 8.0.60, 8.0.61, 8.0.62, 8.0.63, 8.0.64, 8.0.65, 8.0.66, 8.0.67, 8.0.68, 8.0.69, 8.0.70, 8.0.71, 8.0.72, 8.0.73, 8.0.74, 8.0.75, 8.0.76, 8.0.77, 8.0.78, 8.0.79, 8.0.80, 8.0.81, 8.0.82, 8.0.83, 8.0.84, 8.0.85, 8.0.86, 8.0.87, 8.0.88, 8.0.89, 8.0.90, 8.0.91, 8.0.92, 8.0.93, 8.0.94, 8.0.95, 8.0.96, 8.0.97, 8.0.98, 8.0.99, 8.0.100, 8.0.101, 8.0.102, 8.0.103, 8.0.104, 8.0.105, 8.0.106, 8.0.107, 8.0.108, 8.0.109, 8.0.110, 8.0.111, 8.0.112, 8.0.113, 8.0.114, 8.0.115, 8.0.116, 8.0.117, 8.0.118, 8.0.119, 8.0.120, 8.0.121, 8.0.122, 8.0.123, 8.0.124, 8.0.125, 8.0.126, 8.0.127, 8.0.128, 8.0.130, 8.0.131, 8.0.132, 8.0.133, 8.0.134, 8.0.135, 8.0.136, 8.0.137, 8.0.138, 8.0.139, 8.0.140, 8.0.141, 8.0.142, 8.0.143, 8.0.144, 8.0.145, 8.0.146, 8.0.147, 8.0.148, 8.0.149, 8.0.150, 8.0.151, 8.0.152, 8.0.153, 8.0.154, 8.0.155, 8.0.156, 8.0.157, 8.0.158, 8.0.159, 8.0.160, 8.0.161, 8.0.162, 8.0.163, 8.0.164, 8.0.165, 8.0.166, 8.0.167, 8.0.168, 8.0.169, 8.0.170, 8.0.171, 8.0.172, 8.0.173, 8.0.175, 8.0.176, 8.0.178, 8.0.179, 8.0.180, 8.0.181, 8.0.182, 8.0.183, 8.0.184, 8.0.185, 8.0.186, 8.0.187, 8.0.188, 8.0.189, 8.0.190, 8.0.191, 8.0.192, 8.0.193, 8.0.194, 8.0.195, 8.0.196, 8.0.197, 8.0.198, 8.0.199, 8.0.200, 8.0.201, 8.0.202, 8.0.203, 8.0.204, 8.0.205, 8.0.206, 8.0.207, 8.0.208, 8.0.209, 8.0.210, 8.0.211, 8.0.212, 8.0.213, 8.0.214, 8.0.215, 8.0.216, 8.0.217, 8.0.218, 8.0.219, 8.0.220, 8.0.221, 8.0.222, 8.0.223, 8.0.224, 8.0.225, 8.0.226, 8.0.227, 8.0.228, 8.0.229, 8.0.230, 8.0.231, 8.0.232, 8.0.233, 8.0.234, 8.0.235, 8.0.236, 8.0.237, 8.0.238, 8.0.239, 8.1.0, 8.1.1, 8.1.2, 8.1.3, 8.1.4, 8.1.5, 8.1.6, 8.1.7, 8.1.8, 8.1.9, 8.1.10, 8.1.11, 8.1.12, 8.1.13, 8.1.14, 8.1.15, 8.1.16, 8.1.17, 8.1.18, 8.1.19, 8.1.20, 8.1.22, 8.1.23, 8.1.24, 8.1.25, 8.1.26, 8.1.27, 8.1.28, 8.1.29, 8.1.30, 8.1.32, 8.1.33, 8.1.34, 8.1.35, 8.1.36, 8.1.37, 8.1.38, 8.1.39, 8.1.40, 8.1.41, 8.1.42, 8.1.43, 8.1.44, 8.1.45, 8.1.46, 8.1.47, 8.2.0, 8.2.1, 8.2.2, 8.2.3, 8.2.4, 8.2.5, 8.2.6, 8.2.8, 8.2.9, 8.2.10, 8.2.11, 8.2.12, 8.2.13, 8.2.14, 8.2.15, 8.2.16, 8.2.17, 8.2.18, 8.2.19, 8.2.20, 8.2.21, 8.2.22, 8.2.23, 8.2.24, 8.2.25, 8.2.26, 8.2.27, 8.2.28, 8.2.29, 8.2.30, 8.2.31, 8.2.32, 8.2.33, 8.2.34, 8.2.35, 8.2.36, 8.2.37, 8.2.38, 8.2.39, 8.2.40, 8.2.41, 8.2.42, 8.2.43, 8.2.44, 8.2.45, 8.2.46, 8.2.48, 8.2.49, 8.2.50, 8.2.51, 8.2.52, 8.2.53, 8.2.54, 8.2.55, 8.2.56, 8.2.57, 8.2.58, 8.2.59, 8.2.60, 8.2.61, 8.2.62, 8.2.63, 8.2.64, 8.2.65, 8.2.66, 8.2.67, 8.2.68, 8.2.69, 8.2.70, 8.2.71, 8.2.72, 8.2.73, 8.2.74, 8.2.75, 8.2.76, 8.2.77, 8.2.78, 8.2.79, 8.2.80, 8.2.81, 8.2.82, 8.2.83, 8.2.84, 8.2.85, 8.2.86, 8.2.87, 8.2.88, 8.2.89, 8.2.90, 8.2.91, 8.2.92, 8.2.93, 8.2.94, 8.2.95, 8.2.96, 8.2.97, 8.2.98, 8.2.99, 8.2.100, 8.2.101, 8.2.102, 8.2.103, 8.3.0, 8.3.1, 8.3.2, 8.3.3, 8.3.4, 8.3.5, 8.3.6, 8.3.7, 8.3.8, 8.3.9, 8.3.10, 8.3.11, 8.3.12, 8.3.13, 8.3.14, 8.3.15, 8.3.16, 8.3.17, 8.3.18, 8.3.19, 8.3.20, 8.3.21, 8.3.22, 8.3.23, 8.3.24, 8.3.25, 8.3.26, 8.3.27, 8.3.28, 8.3.29, 8.3.30, 8.3.31, 8.3.32, 8.3.33, 8.3.34, 8.3.35, 8.3.36, 8.3.37, 8.3.38, 8.3.39, 8.3.40, 8.3.43, 8.3.44, 8.3.47, 8.3.48, 8.3.49, 8.3.50, 8.3.51, 8.3.52, 8.3.53, 8.3.54, 8.3.55, 8.3.56, 8.3.57, 8.3.58, 8.3.59, 8.3.60, 8.3.61, 8.3.62, 8.3.63, 8.3.64, 8.3.65, 8.3.66, 8.3.67, 8.3.68, 8.3.69, 8.3.70, 8.3.71, 8.3.72, 8.3.73, 8.3.74, 8.3.75, 8.3.76, 8.3.77, 8.3.78, 8.3.79, 8.3.80, 8.3.81, 8.3.82, 8.3.83, 8.3.84, 8.3.85, 8.3.86, 8.3.87, 8.3.88, 8.3.89, 8.3.90, 8.3.91, 8.3.92, 8.3.93, 8.3.94, 8.3.95, 8.3.96, 8.3.97, 8.3.98, 8.3.99, 8.3.100, 8.3.101, 8.3.102, 8.3.103, 8.3.104)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for ultralytics==8.0.20\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting supervision==0.15.0\n",
            "  Downloading supervision-0.15.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: matplotlib<4.0.0,>=3.7.1 in /usr/local/lib/python3.11/dist-packages (from supervision==0.15.0) (3.10.0)\n",
            "Collecting numpy<2.0.0,>=1.20.0 (from supervision==0.15.0)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m981.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: opencv-python-headless<5.0.0.0,>=4.8.0.74 in /usr/local/lib/python3.11/dist-packages (from supervision==0.15.0) (4.11.0.86)\n",
            "Collecting pillow<11.0,>=9.4 (from supervision==0.15.0)\n",
            "  Downloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=6.0 in /usr/local/lib/python3.11/dist-packages (from supervision==0.15.0) (6.0.2)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from supervision==0.15.0) (1.14.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.1->supervision==0.15.0) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.1->supervision==0.15.0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.1->supervision==0.15.0) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.1->supervision==0.15.0) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.1->supervision==0.15.0) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.1->supervision==0.15.0) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib<4.0.0,>=3.7.1->supervision==0.15.0) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib<4.0.0,>=3.7.1->supervision==0.15.0) (1.17.0)\n",
            "Downloading supervision-0.15.0-py3-none-any.whl (69 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.0/69.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-10.4.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pillow, numpy, supervision\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.1.0\n",
            "    Uninstalling pillow-11.1.0:\n",
            "      Successfully uninstalled pillow-11.1.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "Successfully installed numpy-1.26.4 pillow-10.4.0 supervision-0.15.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "51435c9a27cf4c3a88ea345f1262842e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (10.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m86.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m45.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "^C\n",
            "^C\n",
            "^C\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 2: استيراد المكتبات اللازمة\n",
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "import torch\n",
        "import supervision as sv\n",
        "from pathlib import Path\n",
        "from IPython.display import display, HTML\n",
        "from tqdm.notebook import tqdm\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from ultralytics import YOLO\n",
        "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "5c783wvhPLQx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "outputId": "38ee3e04-8a65-4b02-df12-d08eb8f8025f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'ultralytics'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-9ef9570dee45>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLSTM\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDense\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDropout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallbacks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mEarlyStopping\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0multralytics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdeep_sort_realtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepsort_tracker\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDeepSort\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'ultralytics'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 3: تهيئة الإعدادات\n",
        "# تثبيت Google Drive للوصول إلى البيانات\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# إنشاء مجلدات لتخزين البيانات والنماذج\n",
        "MODELS_DIR = '/content/models'\n",
        "DATA_DIR = '/content/data'\n",
        "VIDEOS_DIR = '/content/videos'\n",
        "FRAMES_DIR = '/content/frames'\n",
        "TRACKS_DIR = '/content/tracks'\n",
        "RESULTS_DIR = '/content/results'\n",
        "\n",
        "for directory in [MODELS_DIR, DATA_DIR, VIDEOS_DIR, FRAMES_DIR, TRACKS_DIR, RESULTS_DIR]:\n",
        "    os.makedirs(directory, exist_ok=True)"
      ],
      "metadata": {
        "id": "7FwtGFcSPG1E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 4: تنزيل مقاطع فيديو لمباريات برشلونة من YouTube\n",
        "def download_youtube_video(youtube_id, output_path):\n",
        "    \"\"\"تنزيل فيديو من YouTube باستخدام youtube-dl\"\"\"\n",
        "    !pip install -q yt-dlp\n",
        "    !yt-dlp -f 'bestvideo[ext=mp4][height<=720]+bestaudio[ext=m4a]/best[ext=mp4]/best' \\\n",
        "        -o {output_path} \\\n",
        "        https://www.youtube.com/watch?v={youtube_id}\n",
        "\n",
        "# قائمة بمعرفات فيديوهات لمباريات برشلونة على YouTube\n",
        "# يمكن تحديث هذه القائمة بمباريات أخرى\n",
        "BARCELONA_MATCHES = {\n",
        "    'barca_vs_real_madrid': 'aMaW5JtIuJA',  # برشلونة ضد ريال مدريد\n",
        "    'barca_vs_atletico': 'hKKXGiEFMBbltV88',     # برشلونة ضد أتلتيكو مدريد\n",
        "    'barca_vs_sevilla': 'EnZ0JfD_U4c'       # برشلونة ضد إشبيلية\n",
        "}\n",
        "\n",
        "# تنزيل الفيديوهات\n",
        "for match_name, youtube_id in BARCELONA_MATCHES.items():\n",
        "    output_path = f\"{VIDEOS_DIR}/{match_name}.mp4\"\n",
        "    if not os.path.exists(output_path):\n",
        "        print(f\"تنزيل {match_name}...\")\n",
        "        download_youtube_video(youtube_id, output_path)\n",
        "    else:\n",
        "        print(f\"الفيديو {match_name} موجود بالفعل\")\n",
        "\n",
        "# بديلاً عن ذلك: تنزيل مجموعة بيانات SoccerNet للمباريات المسجلة\n",
        "def download_soccernet_dataset():\n",
        "    \"\"\"تنزيل عينة من مجموعة بيانات SoccerNet\"\"\"\n",
        "    !pip install -q gdown\n",
        "    # رابط لعينة من مجموعة بيانات SoccerNet (تنزيل مباشر من Google Drive)\n",
        "    !gdown --id 1zBVATJCX9KeUQABRr0e-3Jfuue8WvQR3 -O {DATA_DIR}/soccernet_sample.zip\n",
        "    !unzip -q {DATA_DIR}/soccernet_sample.zip -d {DATA_DIR}\n",
        "\n",
        "# تنزيل مجموعة البيانات (يمكن تعليق هذا السطر إذا كنت تستخدم فيديوهات YouTube فقط)\n",
        "# download_soccernet_dataset()"
      ],
      "metadata": {
        "id": "vHYZ10gAP6Ab"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 1: تثبيت الأدوات المطلوبة\n",
        "!pip install -q yt-dlp\n",
        "\n",
        "# Cell 2: استيراد المكتبات\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Cell 3: تهيئة الإعدادات\n",
        "# تثبيت Google Drive للوصول إلى البيانات\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# إنشاء مجلدات لتخزين البيانات والنماذج\n",
        "MODELS_DIR = '/content/models'\n",
        "DATA_DIR = '/content/data'\n",
        "VIDEOS_DIR = '/content/videos'\n",
        "FRAMES_DIR = '/content/frames'\n",
        "TRACKS_DIR = '/content/tracks'\n",
        "RESULTS_DIR = '/content/results'\n",
        "\n",
        "for directory in [MODELS_DIR, DATA_DIR, VIDEOS_DIR, FRAMES_DIR, TRACKS_DIR, RESULTS_DIR]:\n",
        "    os.makedirs(directory, exist_ok=True)\n",
        "\n",
        "# Cell 4: دالة لتحميل الفيديوهات من يوتيوب\n",
        "def download_youtube_video(youtube_id, output_path):\n",
        "    \"\"\"تنزيل فيديو من YouTube باستخدام yt-dlp\"\"\"\n",
        "    !yt-dlp -f 'bestvideo[ext=mp4][height<=720]+bestaudio[ext=m4a]/best[ext=mp4]/best' \\\n",
        "        -o {output_path} \\\n",
        "        https://www.youtube.com/watch?v={youtube_id}\n",
        "\n",
        "# Cell 5: روابط مباريات برشلونة (شغالة)\n",
        "BARCELONA_MATCHES = {\n",
        "    'barca_vs_real_madrid_2025': 'YsWzugAnsBw',     # برشلونة 5-2 ريال مدريد - نهائي السوبر 2025\n",
        "    'barca_vs_real_madrid_2023': 'lPRW7d0B3BE',     # ريال مدريد 3-2 برشلونة - الدوري الإسباني 2023\n",
        "    'barca_vs_real_madrid_friendly_2023': 'TFRpUANNVeg'  # برشلونة 3-0 ريال مدريد - ودية 2023\n",
        "}\n",
        "\n",
        "# Cell 6: تحميل الفيديوهات\n",
        "for match_name, youtube_id in BARCELONA_MATCHES.items():\n",
        "    output_path = f\"{VIDEOS_DIR}/{match_name}.mp4\"\n",
        "    if not os.path.exists(output_path):\n",
        "        print(f\"تنزيل {match_name}...\")\n",
        "        download_youtube_video(youtube_id, output_path)\n",
        "    else:\n",
        "        print(f\"الفيديو {match_name} موجود بالفعل\")\n"
      ],
      "metadata": {
        "id": "7imyV6O5SQCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cell 5: تنزيل وتهيئة نموذج YOLOv8 للكشف عن اللاعبين\n",
        "def setup_yolo_model():\n",
        "    \"\"\"تنزيل وتهيئة نموذج YOLOv8 للكشف عن الأشخاص\"\"\"\n",
        "    # تنزيل النموذج المدرب مسبقًا YOLOv8x\n",
        "    model = YOLO('yolov8x.pt')\n",
        "    return model\n",
        "\n",
        "# تهيئة نموذج YOLOv8\n",
        "yolo_model = setup_yolo_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YncW9pU2SXjY",
        "outputId": "6cda7eed-3ce0-46f4-9708-4c3e6dec448d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8x.pt to 'yolov8x.pt'...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 131M/131M [00:00<00:00, 284MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 6: تهيئة نظام التتبع DeepSORT\n",
        "def setup_tracker():\n",
        "    \"\"\"تهيئة متتبع DeepSORT\"\"\"\n",
        "    tracker = DeepSort(\n",
        "        max_age=30,  # عدد الإطارات التي سيستمر فيها المسار بدون اكتشاف\n",
        "        n_init=3,   # عدد الإطارات اللازمة لتأكيد المسار\n",
        "        nms_max_overlap=1.0,\n",
        "        max_cosine_distance=0.3,\n",
        "        nn_budget=100\n",
        "    )\n",
        "    return tracker"
      ],
      "metadata": {
        "id": "eCYbjdo5SbVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 7: استخراج وتتبع اللاعبين من فيديو\n",
        "def process_video(video_path, output_dir, max_frames=1000):\n",
        "    \"\"\"\n",
        "    معالجة الفيديو للكشف عن اللاعبين وتتبعهم\n",
        "\n",
        "    المدخلات:\n",
        "        video_path: مسار الفيديو\n",
        "        output_dir: دليل حفظ النتائج\n",
        "        max_frames: الحد الأقصى للإطارات للمعالجة (للتطوير السريع)\n",
        "\n",
        "    المخرجات:\n",
        "        df_tracks: إطار بيانات يحتوي على مسارات اللاعبين\n",
        "    \"\"\"\n",
        "    print(f\"معالجة الفيديو: {video_path}\")\n",
        "    video_name = os.path.basename(video_path).split('.')[0]\n",
        "\n",
        "    # إنشاء دليل للإطارات المعالجة لهذا الفيديو\n",
        "    frames_dir = os.path.join(FRAMES_DIR, video_name)\n",
        "    os.makedirs(frames_dir, exist_ok=True)\n",
        "\n",
        "    # إنشاء مجلد لتخزين نتائج التتبع\n",
        "    tracks_path = os.path.join(TRACKS_DIR, f\"{video_name}_tracks.csv\")\n",
        "\n",
        "    # التحقق مما إذا كانت النتائج موجودة بالفعل\n",
        "    if os.path.exists(tracks_path):\n",
        "        print(f\"تم العثور على نتائج التتبع المخزنة مسبقًا: {tracks_path}\")\n",
        "        return pd.read_csv(tracks_path)\n",
        "\n",
        "    # فتح الفيديو\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "    # تهيئة المتتبع\n",
        "    tracker = setup_tracker()\n",
        "\n",
        "    # قائمة لتخزين بيانات المسارات\n",
        "    tracks_data = []\n",
        "\n",
        "    # معالجة الإطارات\n",
        "    frame_idx = 0\n",
        "    progress_bar = tqdm(total=min(int(cap.get(cv2.CAP_PROP_FRAME_COUNT)), max_frames))\n",
        "\n",
        "    while cap.isOpened() and frame_idx < max_frames:\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "\n",
        "        # اكتشاف الأشخاص باستخدام YOLOv8\n",
        "        results = yolo_model(frame, classes=[0])  # الفئة 0 هي \"شخص\"\n",
        "\n",
        "        detections = []\n",
        "        for r in results:\n",
        "            boxes = r.boxes\n",
        "            for box in boxes:\n",
        "                x1, y1, x2, y2 = box.xyxy[0].cpu().numpy()\n",
        "                conf = box.conf[0].cpu().numpy()\n",
        "                cls = box.cls[0].cpu().numpy()\n",
        "\n",
        "                # تنسيق DeepSORT: [x1, y1, x2, y2, confidence]\n",
        "                detection = [int(x1), int(y1), int(x2), int(y2), float(conf)]\n",
        "                detections.append(detection)\n",
        "\n",
        "        # تحديث المتتبع بالاكتشافات الجديدة\n",
        "        tracks = tracker.update_tracks(detections, frame=frame)\n",
        "\n",
        "        # احفظ الإطار بالاكتشافات (للتحقق البصري)\n",
        "        if frame_idx % 10 == 0:  # حفظ كل 10 إطارات\n",
        "            annotated_frame = frame.copy()\n",
        "\n",
        "            # رسم المستطيلات والمعرفات على الإطار\n",
        "            for track in tracks:\n",
        "                if not track.is_confirmed():\n",
        "                    continue\n",
        "\n",
        "                track_id = track.track_id\n",
        "                ltrb = track.to_ltrb()\n",
        "\n",
        "                # رسم المستطيل والمعرف\n",
        "                cv2.rectangle(annotated_frame,\n",
        "                              (int(ltrb[0]), int(ltrb[1])),\n",
        "                              (int(ltrb[2]), int(ltrb[3])),\n",
        "                              (0, 255, 0), 2)\n",
        "                cv2.putText(annotated_frame,\n",
        "                            f\"ID: {track_id}\",\n",
        "                            (int(ltrb[0]), int(ltrb[1] - 10)),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                            0.5, (0, 255, 0), 2)\n",
        "\n",
        "            # حفظ الإطار المشروح\n",
        "            frame_path = os.path.join(frames_dir, f\"frame_{frame_idx:04d}.jpg\")\n",
        "            cv2.imwrite(frame_path, annotated_frame)\n",
        "\n",
        "        # استخراج بيانات المسار لكل لاعب\n",
        "        for track in tracks:\n",
        "            if not track.is_confirmed():\n",
        "                continue\n",
        "\n",
        "            track_id = track.track_id\n",
        "            ltrb = track.to_ltrb()\n",
        "\n",
        "            # حساب المركز\n",
        "            center_x = (ltrb[0] + ltrb[2]) / 2\n",
        "            center_y = (ltrb[1] + ltrb[3]) / 2\n",
        "\n",
        "            # تخزين بيانات المسار\n",
        "            tracks_data.append({\n",
        "                'frame': frame_idx,\n",
        "                'track_id': track_id,\n",
        "                'x': center_x / width,  # تطبيع للعرض\n",
        "                'y': center_y / height,  # تطبيع للارتفاع\n",
        "                'width': (ltrb[2] - ltrb[0]) / width,  # عرض الصندوق المطبع\n",
        "                'height': (ltrb[3] - ltrb[1]) / height,  # ارتفاع الصندوق المطبع\n",
        "                'time': frame_idx / fps,  # الوقت بالثواني\n",
        "            })\n",
        "\n",
        "        frame_idx += 1\n",
        "        progress_bar.update(1)\n",
        "\n",
        "    cap.release()\n",
        "    progress_bar.close()\n",
        "\n",
        "    # تحويل البيانات إلى إطار بيانات وحفظها\n",
        "    df_tracks = pd.DataFrame(tracks_data)\n",
        "    df_tracks.to_csv(tracks_path, index=False)\n",
        "\n",
        "    print(f\"تم معالجة {frame_idx} إطارات وتتبع {df_tracks['track_id'].nunique()} لاعب\")\n",
        "    return df_tracks\n"
      ],
      "metadata": {
        "id": "Hn_jsLngToyQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 8: تحليل بيانات المسار وإعداد البيانات للتدريب\n",
        "def analyze_player_movements(df_tracks, video_name):\n",
        "    \"\"\"\n",
        "    تحليل حركات اللاعبين واستخراج الميزات ذات الصلة\n",
        "\n",
        "    المدخلات:\n",
        "        df_tracks: إطار بيانات يحتوي على بيانات المسار\n",
        "        video_name: اسم الفيديو للتسمية\n",
        "\n",
        "    المخرجات:\n",
        "        df_features: إطار بيانات بميزات الحركة\n",
        "    \"\"\"\n",
        "    print(f\"تحليل حركات اللاعبين في {video_name}...\")\n",
        "\n",
        "    # تصفية المسارات القصيرة جدًا\n",
        "    min_track_length = 50  # الحد الأدنى لطول المسار\n",
        "    track_lengths = df_tracks.groupby('track_id').size()\n",
        "    valid_tracks = track_lengths[track_lengths >= min_track_length].index\n",
        "    df_filtered = df_tracks[df_tracks['track_id'].isin(valid_tracks)]\n",
        "\n",
        "    # استخراج ميزات الحركة\n",
        "    features = []\n",
        "\n",
        "    for track_id, group in df_filtered.groupby('track_id'):\n",
        "        # ترتيب حسب الإطار\n",
        "        group = group.sort_values('frame')\n",
        "\n",
        "        # حساب السرعة (التغير في الموضع)\n",
        "        group['dx'] = group['x'].diff()\n",
        "        group['dy'] = group['y'].diff()\n",
        "        group['speed'] = np.sqrt(group['dx']**2 + group['dy']**2)\n",
        "\n",
        "        # حساب التسارع\n",
        "        group['acceleration'] = group['speed'].diff()\n",
        "\n",
        "        # حساب الاتجاه (بالراديان)\n",
        "        group['direction'] = np.arctan2(group['dy'], group['dx'])\n",
        "\n",
        "        # تقسيم البيانات إلى مقاطع زمنية\n",
        "        window_size = 15  # عدد الإطارات في النافذة الزمنية\n",
        "        stride = 5       # خطوة التحريك\n",
        "\n",
        "        for i in range(0, len(group) - window_size, stride):\n",
        "            window = group.iloc[i:i+window_size]\n",
        "\n",
        "            # حساب الإحصاءات في هذه النافذة\n",
        "            feature_dict = {\n",
        "                'track_id': track_id,\n",
        "                'video': video_name,\n",
        "                'start_frame': window['frame'].iloc[0],\n",
        "                'end_frame': window['frame'].iloc[-1],\n",
        "                'mean_x': window['x'].mean(),\n",
        "                'mean_y': window['y'].mean(),\n",
        "                'std_x': window['x'].std(),\n",
        "                'std_y': window['y'].std(),\n",
        "                'mean_speed': window['speed'].mean(),\n",
        "                'max_speed': window['speed'].max(),\n",
        "                'mean_acceleration': window['acceleration'].mean(),\n",
        "                'direction_change': window['direction'].diff().abs().sum(),\n",
        "                # الحركة في الاتجاه X و Y\n",
        "                'x_displacement': window['x'].iloc[-1] - window['x'].iloc[0],\n",
        "                'y_displacement': window['y'].iloc[-1] - window['y'].iloc[0],\n",
        "                # إضافة تسلسل الإحداثيات X و Y للاستخدام في LSTM\n",
        "                'x_sequence': window['x'].tolist(),\n",
        "                'y_sequence': window['y'].tolist(),\n",
        "                'speed_sequence': window['speed'].tolist(),\n",
        "            }\n",
        "\n",
        "            features.append(feature_dict)\n",
        "\n",
        "    # تحويل إلى إطار بيانات\n",
        "    df_features = pd.DataFrame(features)\n",
        "\n",
        "    # حفظ الميزات\n",
        "    features_path = os.path.join(DATA_DIR, f\"{video_name}_features.csv\")\n",
        "    df_features.drop(['x_sequence', 'y_sequence', 'speed_sequence'], axis=1).to_csv(features_path, index=False)\n",
        "\n",
        "    return df_features\n",
        "\n",
        "# Cell 9: تصنيف نمط اللعب وتجميع البيانات\n",
        "def classify_playing_patterns(df_features, num_clusters=4):\n",
        "    \"\"\"\n",
        "    تصنيف أنماط اللعب باستخدام التجميع\n",
        "\n",
        "    المدخلات:\n",
        "        df_features: إطار بيانات بميزات الحركة\n",
        "        num_clusters: عدد المجموعات\n",
        "\n",
        "    المخرجات:\n",
        "        df_features: إطار بيانات مع تصنيفات النمط\n",
        "    \"\"\"\n",
        "    from sklearn.cluster import KMeans\n",
        "\n",
        "    # تحديد الميزات للتجميع\n",
        "    clustering_features = [\n",
        "        'mean_x', 'mean_y', 'std_x', 'std_y',\n",
        "        'mean_speed', 'max_speed', 'mean_acceleration',\n",
        "        'direction_change', 'x_displacement', 'y_displacement'\n",
        "    ]\n",
        "\n",
        "    # تطبيع البيانات\n",
        "    from sklearn.preprocessing import StandardScaler\n",
        "    scaler = StandardScaler()\n",
        "    scaled_features = scaler.fit_transform(df_features[clustering_features])\n",
        "\n",
        "    # التجميع بـ K-means\n",
        "    kmeans = KMeans(n_clusters=num_clusters, random_state=42)\n",
        "    df_features['pattern_cluster'] = kmeans.fit_predict(scaled_features)\n",
        "\n",
        "    # توصيف المجموعات\n",
        "    cluster_descriptions = {\n",
        "        0: \"هجوم سريع\",\n",
        "        1: \"تراجع دفاعي\",\n",
        "        2: \"استحواذ وسط الملعب\",\n",
        "        3: \"تحرك جانبي\"\n",
        "    }\n",
        "\n",
        "    # إضافة وصف المجموعة\n",
        "    df_features['pattern_description'] = df_features['pattern_cluster'].map(cluster_descriptions)\n",
        "\n",
        "    return df_features"
      ],
      "metadata": {
        "id": "KXHtI267Tq4z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Cell 10: إعداد بيانات التدريب لنموذج LSTM\n",
        "def prepare_lstm_data(df_features):\n",
        "    \"\"\"\n",
        "    إعداد البيانات للتدريب على نموذج LSTM\n",
        "\n",
        "    المدخلات:\n",
        "        df_features: إطار بيانات بميزات الحركة\n",
        "\n",
        "    المخرجات:\n",
        "        X_train, X_test, y_train, y_test: بيانات التدريب والاختبار\n",
        "    \"\"\"\n",
        "    # تحضير المدخلات (تسلسلات x, y) والمخرجات (تسلسلات مستقبلية)\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    sequence_length = 10  # طول تسلسل الإدخال\n",
        "    prediction_steps = 5  # عدد الخطوات المستقبلية للتنبؤ\n",
        "\n",
        "    for _, row in df_features.iterrows():\n",
        "        x_seq = row['x_sequence']\n",
        "        y_seq = row['y_sequence']\n",
        "\n",
        "        if len(x_seq) < sequence_length + prediction_steps:\n",
        "            continue\n",
        "\n",
        "        # استخدام تسلسل الإدخال للتنبؤ بالخطوات المستقبلية\n",
        "        for i in range(len(x_seq) - sequence_length - prediction_steps):\n",
        "            x_input = []\n",
        "            for j in range(sequence_length):\n",
        "                x_input.append([x_seq[i+j], y_seq[i+j]])\n",
        "\n",
        "            x_output = []\n",
        "            for j in range(prediction_steps):\n",
        "                x_output.append([x_seq[i+sequence_length+j], y_seq[i+sequence_length+j]])\n",
        "\n",
        "            X.append(x_input)\n",
        "            y.append(x_output)\n",
        "\n",
        "    # تحويل إلى مصفوفات NumPy\n",
        "    X = np.array(X)\n",
        "    y = np.array(y)\n",
        "\n",
        "    # تقسيم إلى مجموعات تدريب واختبار\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    print(f\"شكل بيانات التدريب X: {X_train.shape}, y: {y_train.shape}\")\n",
        "    print(f\"شكل بيانات الاختبار X: {X_test.shape}, y: {y_test.shape}\")\n",
        "\n",
        "    return X_train, X_test, y_train, y_test\n",
        "\n",
        "# Cell 11: بناء وتدريب نموذج LSTM للتنبؤ بحركات اللاعبين\n",
        "def build_lstm_model(X_train, y_train, X_test, y_test):\n",
        "    \"\"\"\n",
        "    بناء وتدريب نموذج LSTM للتنبؤ بحركات اللاعبين\n",
        "\n",
        "    المدخلات:\n",
        "        X_train, y_train: بيانات التدريب\n",
        "        X_test, y_test: بيانات الاختبار\n",
        "\n",
        "    المخرجات:\n",
        "        model: النموذج المدرب\n",
        "    \"\"\"\n",
        "    input_shape = X_train.shape[1:]\n",
        "    output_shape = y_train.shape[1:]\n",
        "\n",
        "    # تحقق من وجود نموذج محفوظ مسبقًا\n",
        "    model_path = os.path.join(MODELS_DIR, 'lstm_player_prediction.h5')\n",
        "    if os.path.exists(model_path):\n",
        "        print(\"تحميل نموذج LSTM محفوظ مسبقًا...\")\n",
        "        model = load_model(model_path)\n",
        "        return model\n",
        "\n",
        "    # بناء نموذج LSTM\n",
        "    model = Sequential([\n",
        "        LSTM(128, return_sequences=True, input_shape=input_shape),\n",
        "        Dropout(0.2),\n",
        "        LSTM(64),\n",
        "        Dropout(0.2),\n",
        "        Dense(np.prod(output_shape))\n",
        "    ])\n",
        "\n",
        "    # إعادة تشكيل طبقة الإخراج\n",
        "    model.add(tf.keras.layers.Reshape(output_shape))\n",
        "\n",
        "    # تجميع النموذج\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='mse'\n",
        "    )\n",
        "\n",
        "    # ملخص النموذج\n",
        "    model.summary()\n",
        "\n",
        "    # تدريب النموذج\n",
        "    early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
        "    model_checkpoint = ModelCheckpoint(model_path, save_best_only=True)\n",
        "\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_test, y_test),\n",
        "        epochs=30,\n",
        "        batch_size=32,\n",
        "        callbacks=[early_stopping, model_checkpoint]\n",
        "    )\n",
        "\n",
        "    # تحليل أداء النموذج\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(history.history['loss'], label='خسارة التدريب')\n",
        "    plt.plot(history.history['val_loss'], label='خسارة التحقق')\n",
        "    plt.title('أداء نموذج التنبؤ LSTM')\n",
        "    plt.xlabel('الحقبة (Epoch)')\n",
        "    plt.ylabel('متوسط مربع الخطأ (MSE)')\n",
        "    plt.legend()\n",
        "    plt.savefig(os.path.join(RESULTS_DIR, 'lstm_training_history.png'))\n",
        "\n",
        "    return model\n"
      ],
      "metadata": {
        "id": "FOJosUjVTwca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Cell 12: تقييم نموذج LSTM\n",
        "def evaluate_lstm_model(model, X_test, y_test):\n",
        "    \"\"\"\n",
        "    تقييم نموذج LSTM على بيانات الاختبار\n",
        "\n",
        "    المدخلات:\n",
        "        model: نموذج LSTM المدرب\n",
        "        X_test, y_test: بيانات الاختبار\n",
        "    \"\"\"\n",
        "    # التنبؤ على بيانات الاختبار\n",
        "    y_pred = model.predict(X_test)\n",
        "\n",
        "    # حساب متوسط مربع الخطأ لكل خطوة زمنية\n",
        "    mse_by_step = np.mean((y_test - y_pred)**2, axis=(0, 2))\n",
        "\n",
        "    # رسم بياني للخطأ حسب الخطوة الزمنية\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(mse_by_step, marker='o')\n",
        "    plt.title('دقة التنبؤ حسب الخطوة الزمنية المستقبلية')\n",
        "    plt.xlabel('خطوة التنبؤ')\n",
        "    plt.ylabel('متوسط مربع الخطأ (MSE)')\n",
        "    plt.grid(True)\n",
        "    plt.savefig(os.path.join(RESULTS_DIR, 'prediction_accuracy_by_step.png'))\n",
        "\n",
        "    # عرض مثال للتنبؤات\n",
        "    num_examples = 5\n",
        "    plt.figure(figsize=(15, 10))\n",
        "\n",
        "    for i in range(num_examples):\n",
        "        plt.subplot(num_examples, 1, i+1)\n",
        "\n",
        "        # الموقع الفعلي\n",
        "        actual_x = y_test[i, :, 0]\n",
        "        actual_y = y_test[i, :, 1]\n",
        "\n",
        "        # الموقع المتوقع\n",
        "        pred_x = y_pred[i, :, 0]\n",
        "        pred_y = y_pred[i, :, 1]\n",
        "\n",
        "        # رسم بياني\n",
        "        plt.plot(actual_x, actual_y, 'b-', marker='o', label='الموقع الفعلي')\n",
        "        plt.plot(pred_x, pred_y, 'r--', marker='x', label='الموقع المتوقع')\n",
        "        plt.title(f'مثال {i+1}: مقارنة بين الموقع الفعلي والمتوقع')\n",
        "        plt.legend()\n",
        "        plt.grid(True)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(RESULTS_DIR, 'prediction_examples.png'))"
      ],
      "metadata": {
        "id": "VQRqqr4rT5TQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# Cell 13: تحليل الأنماط التكتيكية وتوليد التوصيات\n",
        "def tactical_pattern_analysis(df_features):\n",
        "    \"\"\"\n",
        "    تحليل الأنماط التكتيكية وتوليد توصيات للمدرب\n",
        "\n",
        "    المدخلات:\n",
        "        df_features: إطار بيانات بميزات الحركة وتصنيفات النمط\n",
        "    \"\"\"\n",
        "    # تحليل توزيع الأنماط\n",
        "    pattern_distribution = df_features['pattern_description'].value_counts(normalize=True) * 100\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    pattern_distribution.plot(kind='bar', color='skyblue')\n",
        "    plt.title('توزيع الأنماط التكتيكية')\n",
        "    plt.xlabel('النمط التكتيكي')\n",
        "    plt.ylabel('النسبة المئوية (%)')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(RESULTS_DIR, 'tactical_pattern_distribution.png'))\n",
        "\n",
        "    # تحليل السرعة حسب النمط\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.boxplot(x='pattern_description', y='mean_speed', data=df_features)\n",
        "    plt.title('متوسط السرعة حسب النمط التكتيكي')\n",
        "    plt.xlabel('النمط التكتيكي')\n",
        "    plt.ylabel('متوسط السرعة')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(RESULTS_DIR, 'speed_by_pattern.png'))\n",
        "\n",
        "    # خريطة حرارية لمواقع اللاعبين حسب النمط\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    for i, pattern in enumerate(pattern_distribution.index):\n",
        "        plt.subplot(2, 2, i+1)\n",
        "        pattern_data = df_features[df_features['pattern_description'] == pattern]\n",
        "\n",
        "        plt.scatter(pattern_data['mean_x'], pattern_data['mean_y'],\n",
        "                   alpha=0.3, s=10)\n",
        "        plt.title(f'مواقع اللاعبين: {pattern}')\n",
        "        plt.xlim(0, 1)\n",
        "        plt.ylim(0, 1)\n",
        "        plt.gca().set_aspect('equal')\n",
        "\n",
        "        # إضافة خطوط تمثل حدود الملعب\n",
        "        plt.axhline(y=0.5, color='black', linestyle='--', alpha=0.3)  # خط الوسط\n",
        "        plt.axvline(x=0, color='black', alpha=0.3)  # خط المرمى اليسار\n",
        "        plt.axvline(x=1, color='black', alpha=0.3)  # خط المرمى اليمين\n",
        "        plt.axvline(x=0.5, color='black', linestyle='--', alpha=0.3)  # خط المنتصف\n",
        "        plt.xlabel('الموقع الأفقي (x)')\n",
        "        plt.ylabel('الموقع العمودي (y)')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(os.path.join(RESULTS_DIR, 'heatmap_by_pattern.png'))\n",
        "    plt.close()"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "cM3J_5udVDgU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# 1. استخراج بيانات الحركة من التتبع (PBAS)\n",
        "import numpy as np # Import numpy\n",
        "\n",
        "def extract_motion_data(frames, contours_data):\n",
        "    data = []\n",
        "    for i, contours in enumerate(contours_data):\n",
        "        for cnt in contours:\n",
        "            x, y, w, h = cv2.boundingRect(cnt)\n",
        "            center_x, center_y = x + w // 2, y + h // 2\n",
        "            data.append([i, center_x, center_y])\n",
        "    return np.array(data)\n",
        "\n",
        "\n",
        "# 2. تحضير بيانات LSTM\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense\n",
        "\n",
        "def prepare_lstm_data(data, sequence_length=10):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - sequence_length):\n",
        "        X.append(data[i:i + sequence_length, 1:])\n",
        "        y.append(data[i + sequence_length, 1:])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "#  **Placeholder for frames and contours_data - Replace with your actual data**\n",
        "frames = [] # Example: frames = [cv2.imread(frame_path) for frame_path in frame_paths]\n",
        "contours_data = [] # Example: contours_data = [[get_contours(frame)] for frame in frames]\n",
        "\n",
        "# استخراج بيانات الحركة\n",
        "motion_data = extract_motion_data(frames, contours_data)\n",
        "\n",
        "# تطبيع وتحضير البيانات\n",
        "scaler = MinMaxScaler()\n",
        "motion_data_scaled = scaler.fit_transform(motion_data)  # motion_data ناتجة من extract_motion_data\n",
        "X, y = prepare_lstm_data(motion_data_scaled)\n",
        "\n",
        "\n",
        "# 3. تدريب نموذج LSTM\n",
        "model = Sequential()\n",
        "model.add(LSTM(64, input_shape=(X.shape[1], X.shape[2]), return_sequences=False))\n",
        "model.add(Dense(2))  # الإحداثيات (x, y)\n",
        "\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "model.fit(X, y, epochs=20, batch_size=32, validation_split=0.2)\n",
        "\n",
        "\n",
        "# 4. حفظ النتائج وتحليل الأداء\n",
        "predicted = model.predict(X)\n",
        "predicted_coords = scaler.inverse_transform(np.concatenate([np.zeros((predicted.shape[0], 1)), predicted], axis=1))[:, 1:]\n",
        "\n",
        "# حفظ النتائج\n",
        "np.save(\"predicted_coords.npy\", predicted_coords)\n",
        "\n",
        "\n",
        "# 5. واجهة Streamlit\n",
        "# حفظ هذا الجزء في ملف streamlit_app.py لتشغيله بـ `streamlit run streamlit_app.py`\n",
        "\n",
        "import streamlit as st\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "st.title(\"تحليل تحركات اللاعبين باستخدام LSTM\")\n",
        "\n",
        "# تحميل النتائج\n",
        "predicted = np.load(\"predicted_coords.npy\")\n",
        "\n",
        "# عرض النتائج\n",
        "st.subheader(\"المسار المتوقع للحركة\")\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(predicted[:, 0], predicted[:, 1], label=\"LSTM Prediction\", color='blue')\n",
        "st.pyplot(fig)\n",
        "\n",
        "# رفع فيديو للمباراة\n",
        "uploaded_file = st.file_uploader(\"ارفع فيديو لمباراة حقيقية للمقارنة\", type=[\"mp4\"])\n",
        "\n",
        "if uploaded_file is not None:\n",
        "    st.video(uploaded_file)\n",
        "    st.info(\"سيتم تحليل الفيديو لاحقاً وربطه مع النتائج لتقييم أداء النموذج.\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 503
        },
        "id": "vFAHgiDKwXYn",
        "outputId": "5410ed7a-ed3a-4bef-b874-8de63179b617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-d49411525d75>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;31m# تطبيع وتحضير البيانات\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mscaler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m \u001b[0mmotion_data_scaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmotion_data\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# motion_data ناتجة من extract_motion_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprepare_lstm_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmotion_data_scaled\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_set_output.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m         \u001b[0mdata_to_wrap\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_to_wrap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m             \u001b[0;31m# only wrap the first output for cross decomposition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    916\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 918\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    919\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    920\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    445\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 447\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0m_fit_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer_skip_nested_validation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/base.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1387\u001b[0m                 )\n\u001b[1;32m   1388\u001b[0m             ):\n\u001b[0;32m-> 1389\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfit_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m         \u001b[0mfirst_pass\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"n_samples_seen_\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m         X = validate_data(\n\u001b[0m\u001b[1;32m    488\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mvalidate_data\u001b[0;34m(_estimator, X, y, reset, validate_separately, skip_check_array, **check_params)\u001b[0m\n\u001b[1;32m   2942\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2943\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2944\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"X\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2945\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2946\u001b[0m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_writeable, force_all_finite, ensure_all_finite, ensure_non_negative, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[1;32m   1091\u001b[0m                         \u001b[0;34m\"if it contains a single sample.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m                     )\n\u001b[0;32m-> 1093\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1094\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1095\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdtype_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"kind\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m\"USV\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
          ]
        }
      ]
    }
  ]
}
